# crawline

__TODO:__ バッヂ

> Webクローリングとスクレイピングを行う基盤アプリケーション

__TODO:__ Table of Contents

## Security

個人用のアプリケーションであり、複数人数が使用することは想定していない。外部からはジョブ・スケジューラーでジョブを実行するだけ。

そのため、認証機能は実装しない。nginx-proxyの機能でBASIC認証を実装しても良いし、Let's Encryptでサーバー証明書を設定しても良いが、それは外部アプリケーションの役割とする。

## Background

いくつかの似たようなスクレイピング・アプリケーションを作成してきた。新しいサイトのスクレイピング要件はこれからも出続けるだろうし、その度に新しいアプリケーションを作るのは、時間とマシン・リソースの無駄。

そのため、スクレイピングの基盤を構築して、複数のサイトに対するスクレイピングを統合したい。ページに対する解析方法、検証方法、リンク解析方法などを、コードで制御して、気軽に追加・変更できるようにしたい。ページのキャッシュ制御、旧バージョンの管理なども任せたい。

解析後のデータのモデル構築などは、個々のアプリケーションがやるべきだと思っているので、ここではやらない。

## Install

__TODO:__ 基盤コードとルール・コードの管理を分けたい。そのため、gemによる提供を考える

## Usage

### スクレイピングのルールを定義する

__TODO:__ 目的、具体的な手順、例を示す

ページに対する解析、検証、リンク抽出方法は、クラスで定義する。XPathで定義とも考えたが、それだと複雑なページが解析できない気がする。

ダウンロードしたページの保存、キャッシュ制御は基盤が自動的に行う。RFC的なキャッシュ制御のほか、「以前のダウンロードから1か月はキャッシュを使う」などの優先独自ルールを設定可能とする。

クローリング時間間隔、異なるドメインへの平行ダウンロードなど、基盤が制御する。

### URLを起点にクロール、スクレイピングを行う

__TODO:__ 目的、具体的な手順、例を示す

外部からクロールして欲しいURLを指定すると、ルールに従って解析して、リンクを辿れるだけ辿る。

## API

__TODO:__ APIドキュメントへのリンクを示す

## Maintainer

__TODO:__ リンクを示す

- u6k
    - GitHub
    - Twitter
    - Blog

## Contribute

__TODO:__ 書く

## License

[MIT License](https://github.com/u6k/crawline/blob/master/LICENSE)

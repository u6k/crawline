# crawline

> Webクローリングとスクレイピングを行う基盤アプリケーション

## Security

あくまで個人用のアプリケーションであり、複数人が使用することは想定していない。外部からはジョブ・スケジューラーでジョブを実行するだけ。よって、認証機能は実装しない。nginx-proxyの機能でBASIC認証を実装しても良い。

## Background

いくつかの似たようなスクレイピング・アプリケーションを作成した。新しいサイトのスクレイピング要件はこれからも出続けるだろうし、その度に新しいアプリケーションを作るのは、時間とマシン・リソースの無駄。

そのため、スクレイピングの基盤を構築して、ルール・ベースでページの解析方法やリンクの辿り方などを制御したい。ページのキャッシュ制御、旧バージョンの管理なども任せたい。

解析後のデータのモデル構築などは、ここのアプリケーションがやるべきだと思っているので、ここではやらない。

## Features

ページに対する解析、検証、リンク抽出方法は、クラスで定義する。XPathで定義とも考えたが、それだと複雑なページが解析できない気がする。

ダウンロードしたページの保存、キャッシュ制御は基盤が自動的に行う。RFC的なキャッシュ制御のほか、「以前のダウンロードから1か月はキャッシュを使う」などの優先独自ルールを設定可能とする。

外部からクロールして欲しいURLを指定すると、ルールに従って解析して、リンクを辿れるだけ辿る。

クローリング時間間隔、異なるドメインへの平行ダウンロードなど、基盤が制御する。
